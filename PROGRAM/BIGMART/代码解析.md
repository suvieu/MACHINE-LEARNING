### 根据BIGMART提供的各门店和产品的信息(分成train和test两个CSV文件，其中test文件中是没有sales数据的，需要预测)，预测它的销售情况。###

**先看一下BIGMART 提供了哪些信息？**

**Item_Identifier：商品编号**

**Item_Weight：商品重量**

**Item_Fat_Content：商品含脂肪的程度，有两种：Low和Regular**

**Item_Visibility：商品被顾客看见的容易程度**

**Item_Type：商品的种类**

**Outlet_Identifier：门店编号**

**Outlet_Establishment_Year：门店创建时间**

**Outlet_Size：门店大小，有三种 High，Medium，Small**


**Outlet_Location_Type：门店的地段，分三级**

**tlet_Type：门店的种类**

**Item_Outlet_Sales：商品的销售额**

<br>

**首先导入CSV文件，添加一列Outlet_Age表示门店成立了多久**


```python
train=pd.read_csv('bigmart_train.csv')
train['Outlet_Age']=2020-train['Outlet_Establishment_Year']
```
<br>

**查看有哪些数据缺失，发现Item_Weight有1463行缺少数据，Outlet_Size有2410行数据缺少**
![image](https://github.com/suvieu/MACHINE-LEARNING/blob/master/PROGRAM/BIGMART/1.png)

<br>

**Item_Weight用平均数代替空缺；Outlet_Size用众数(Medium)替换**
```python
print(train.isnull().sum())
train['Outlet_Size']=train['Outlet_Size'].fillna(train['Outlet_Size'].mode()[0])
train['Item_Weight']=train['Item_Weight'].fillna(train['Item_Weight'].mean())
```
<br>

**查看Item_Visibility，筛选异常值，大于Q3 1.5倍IQR或小于Q1 1.5倍IQR的值为异常值，将其剔除**

```python
Q1=train['Item_Visibility'].quantile(0.25)
Q3=train['Item_Visibility'].quantile(0.75)
IQR=Q3-Q1
filt_train=train.query('(@Q1-1.5*@IQR)<=Item_Visibility<=(@Q3+1.5*@IQR)')
train=filt_train
```
<br>

**用cut方法将Item_Visibility分成三类，‘Low Viz','Viz','High Viz**
**空缺值全部替换成Low Viz**

```python
train['Item_Visibility_bins']=pd.cut(train['Item_Visibility'],(0.000,0.065,0.13,0.2),labels=['Low Viz','Viz','High Viz'])
print(train['Item_Visibility_bins'].value_counts())
train['Item_Visibility_bins']=train['Item_Visibility_bins'].replace(np.nan,'Low Viz',regex=True)
```
<br>

**查看Item_Fat_Content，发现虽然只有Low Fat和Regular两种分类，但有多种不同的表现方式，用replace将其统一起来**

```python
train['Item_Fat_Content']=train['Item_Fat_Content'].replace(['LF','low fat'],'Low Fat')
train['Item_Fat_Content']=train['Item_Fat_Content'].replace('reg','Regular')
```

**Item_Fat_Content/Item_Visibility_bins/Outlet_Size/Outlet_Location_Type/Outlet_Type 这几列是文本型数据，需要转换成数值型数据。**
**因为Item_Fat_Content/Item_Visibility_bins/Outlet_Size/Outlet_Location_Type 这四列下的数据是定序的，即各元素之间有比较大小的，
比如lwo fat 比Regular要低；Tier1比tier3要低**
**所以用labelcoder转换成数值1，2，3来显示他们各自之间的比较关系即可 **
**而Outlet_Type下的数据之间是没有大小关系的，用get dummy方法转化成 0和1的数值。**

```python
train['Item_Fat_Content']=le.fit_transform(train['Item_Fat_Content'])
train['Item_Visibility_bins']=le.fit_transform(train['Item_Visibility_bins'])
train['Outlet_Size']=le.fit_transform(train['Outlet_Size'])
train['Outlet_Location_Type']=le.fit_transform(train['Outlet_Location_Type'])
dummy=pd.get_dummies(train['Outlet_Type'])
train=pd.concat([train,dummy],axis=1)
```
<br>

**至此数据基本清洗完毕，下面进行机器学习，对test里的数据进行预测,test文件里的数据也需要清洗，方法同上，这里不在赘述。**
**首先将dataframe分成feature和target**
```python
x=train.drop('Item_Outlet_Sales',axis=1)
y=train['Item_Outlet_Sales']

**将train里的数据分为训练集和测试集**
**用训练集训练，再用测试集测试预测的值是否准确**
```python
x_train, x_test, y_train, y_test = model_selection.train_test_split(x, y, test_size = 0.3, random_state =42)
Lin=LinearRegression()
Lin.fit(x_train,y_train)
prediction=Lin.predict(x_test)
print(sqrt(mean_squared_error(y_test,prediction)))
```
**得到的RMSE值为1118**

**最后用test CSV文件中的数据进行预测**
```python
prediction2=Lin.predict(X_test)
print(prediction2)
```




